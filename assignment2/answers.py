a1a=['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']
a1b=2649
a1c=12.05988565013656
a1d='function'
a2a=13
a2b=2.4630453700815003
a4a3=0.8689827219809665
a4b1=[('``', '.'), ('My', 'DET'), ('taste', 'NOUN'), ('is', 'VERB'), ('gaudy', 'ADV'), ('.', '.')]
a4b2=[('``', '.'), ('My', 'DET'), ('taste', 'NOUN'), ('is', 'VERB'), ('gaudy', 'ADJ'), ('.', '.')]
a4b3="The HMM model can only capture 2-word history, not long-range dependencies. 'gaudy' is for 'taste', but HMM model only knows it follows a VERB, so tags it as ADV rather than ADJ. Because ADV is more likely follows a VERB, and 'gaudy' has similar cost being ADJ or ADV."
a4c=56.630575309531835
a4d=308.71227854747974
a4e=['DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADV']
a5='When no global ambiguities and no unkonw words, the original parser only have 1 valid output, we directly use the output. If there are global ambiguities, the original parser has multiple valid results, use the pre-trained POS tagger to find the most likely one. And if there are unknown words, use the pre-trained tagger to find the most likely tag of that word depends on the transition probabilitiy. So it always better or as well as the original parser.'
a6='If we use the original tagset, the accuracy on the test set will be much lower. Because with more tags, each tag/word pair has less ovservations, so we have few confidence level on the probability model. And more tags depends on long-range effects, but HMM nodel only catch 2 word history, so they are more errors. And using large complex tagset the annotor is more likely to make errors. Thus the overall accuracy will be lower.'
a3c=16.79319240474419
a3d='<s>'
